{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! pip install -U scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "import sklearn\n",
    "import csv\n",
    "print(sklearn.__version__)\n",
    "print(csv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import dataset as dt\n",
    "import training as tr\n",
    "import preprocessing as tp\n",
    "import model as m\n",
    "import evaluation as eva\n",
    "import utils\n",
    "import config\n",
    "# import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, precision_score#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: count-vect-xgboost\n",
      "---------------------------\n",
      "allergens dataset\n",
      "---------------------------\n",
      "Is it cleaned by Parker engine? True\n",
      "---------------------------\n",
      "feature ingredients\n",
      "---------------------------\n",
      "labels ['nuts', 'milk', 'gluten', 'soy', 'peanut', 'eggs']\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "parker =  True #True #False #\n",
    "# dataset names\n",
    "data_index = 2\n",
    "if data_index == 2 : j = 0\n",
    "else: j = 1\n",
    "dataset = config.datasets[data_index] #dt.Allergens\n",
    "partial_key = dataset['keys'][0]\n",
    "labels = dataset['labels']\n",
    "feature = dataset['features'][0]\n",
    "dataName = dataset['data_dir']\n",
    "\n",
    "#LEARNING ALGORITHM\n",
    "alg = config.classifier #'multinomial bayesian' #'xgboost'\n",
    "#LANGUAGE MODEL\n",
    "lang = config.transformers[j] #'tf-idf'\n",
    "#MODEL\n",
    "model_name = m.get_best_ml(data_index) #get_modelName(lang[\"name\"], alg[\"name\"])\n",
    "print('model:', model_name)\n",
    "print('---------------------------')\n",
    "\n",
    "\n",
    "seed = 42\n",
    "\n",
    "print(f'{dataName} dataset')\n",
    "print('---------------------------')\n",
    "print(f'Is it cleaned by Parker engine? {parker}')\n",
    "print('---------------------------')\n",
    "print('feature', feature)\n",
    "print('---------------------------')\n",
    "print('labels', labels)\n",
    "print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parker:\n",
    "    _parker = \"\"\n",
    "    _with = \"with_constraints\"\n",
    "else:\n",
    "    _parker = \"_parker\"\n",
    "    _with = 'with_parker'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configFile ./results/allergens/results_training_best_ml.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configFile = f\"./results/{dataset['data_dir']}/results_training_best_ml.json\"\n",
    "\n",
    "print('configFile', configFile)\n",
    "\n",
    "f = open(configFile)\n",
    "\n",
    "records = json.load(f)\n",
    "\n",
    "encoder = {} \n",
    "for label in labels:\n",
    "    if 'encoder' in records[_with][model_name][label]:\n",
    "        encoder[label] = records[_with][model_name][label]['encoder']\n",
    "    \n",
    "f.close()\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test robustness of the trained model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from evaluator import evaluator as evals\n",
    "\n",
    "ev = evals.Evaluator(dataset, parker, model_name)\n",
    "ev.test_model_robustness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test the trained model and save the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative path ./data/allergens --before delete (1635, 18)\n",
      "--after delete (298, 18)\n",
      "a= nuts [1 0 2]\n",
      "correct repair 11 repairs 44 errors 22\n",
      "nuts stats: PRECISION, RECALL, F1 (0.25, 0.5, 0.33)\n",
      "a= milk [0 2 1]\n",
      "correct repair 2 repairs 33 errors 6\n",
      "milk stats: PRECISION, RECALL, F1 (0.06, 0.33, 0.1)\n",
      "a= gluten [0 2 1]\n",
      "correct repair 5 repairs 26 errors 5\n",
      "gluten stats: PRECISION, RECALL, F1 (0.19, 1.0, 0.32)\n",
      "a= soy [1 0 2]\n",
      "correct repair 4 repairs 28 errors 7\n",
      "soy stats: PRECISION, RECALL, F1 (0.14, 0.57, 0.22)\n",
      "a= peanut [0 2 1]\n",
      "correct repair 14 repairs 29 errors 18\n",
      "peanut stats: PRECISION, RECALL, F1 (0.48, 0.78, 0.59)\n",
      "a= eggs [0 2 1]\n",
      "correct repair 0 repairs 12 errors 0\n",
      "eggs stats: PRECISION, RECALL, F1 (0.0, 0, 0)\n",
      "----------------------------------------\n",
      "correct_repairs, repairs, errors 36 172 58\n",
      "precision 0.21\n",
      "recall 0.62\n",
      "F1 0.3137349397590361\n"
     ]
    }
   ],
   "source": [
    "dtest = dt.read_test_csv(dataName, parker)\n",
    "\n",
    "for a in labels:\n",
    "    if a + '_gs'not in dtest.columns:\n",
    "        dtest = dtest.merge(dt.read_gs_csv(dataName)[[partial_key, a ]], \n",
    "                              how='inner', on=partial_key, suffixes=('', '_gs'))\n",
    "\n",
    "    ## load saved model\n",
    "    file_model_name = f\"./models/_{a}_classifier_{model_name}_{_with}.pth\"\n",
    "    with open(file_model_name, 'rb') as f: model = pickle.load(f)   \n",
    "\n",
    "\n",
    "    # predict the values for the labels to be repaired\n",
    "    enc, y_orig, y_gs = tp.encode(encoder, a, dtest)\n",
    "    y_pred, outputs, dtest, accuracy = tr.clf_test(model, dtest, a, dataset, enc)\n",
    "\n",
    "    print('a=', a, dtest[a].unique())\n",
    "    # metrics\n",
    "    metrics = eva.get_metrics(y_pred, y_orig.values, y_gs.values)\n",
    "    print(a, 'stats: PRECISION, RECALL, F1', metrics)\n",
    "    #break\n",
    "\n",
    "print('----------------------------------------')\n",
    "crs, rs, es = eva.get_all_stats(dtest, labels)\n",
    "print('correct_repairs, repairs, errors', crs, rs, es)\n",
    "print('precision', round(crs/rs,2))\n",
    "if es !=0: \n",
    "    print('recall', round(crs/es,2))\n",
    "    print('F1', 2 * round(crs/rs,2) * round(crs/es,2)/(round(crs/rs,2) + round(crs/es,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save last repaired datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be saved: data/allergens/repaired/allergens_count-vect-xgboost_ML_repair_with_parker.csv\n"
     ]
    }
   ],
   "source": [
    "if not parker:\n",
    "    a = labels[0]\n",
    "    dtest[[a, a+'_gs']][dtest[a] != dtest[a+'_gs']].shape, dtest.shape\n",
    "file = f\"data/{dataset['data_dir']}/repaired/{dataset['data_dir']}_{model_name}_ML_repair_{_with}.csv\"\n",
    "\n",
    "print('File to be saved:', file)\n",
    "#dtest.to_csv(file, quoting=csv.QUOTE_NONNUMERIC, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative path ./data/allergens --before delete (1635, 18)\n",
      "--after delete (298, 18)\n",
      "(298, 18)\n",
      "+++++++++++++++++++++Start+++++++++++++++++++++++++++++\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 9 repairs 19 errors 22\n",
      "$\\tau_a$ 0.83\n",
      "nuts stats: PRECISION, RECALL, F1 (0.47, 0.41, 0.44)\n",
      "------ done replacing ----------\n",
      "(9, 19, 22)\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 2 repairs 22 errors 6\n",
      "$\\tau_a$ 0.87\n",
      "milk stats: PRECISION, RECALL, F1 (0.09, 0.33, 0.14)\n",
      "------ done replacing ----------\n",
      "(2, 22, 6)\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 3 repairs 11 errors 5\n",
      "$\\tau_a$ 0.83\n",
      "gluten stats: PRECISION, RECALL, F1 (0.27, 0.6, 0.37)\n",
      "------ done replacing ----------\n",
      "(3, 11, 5)\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 4 repairs 17 errors 7\n",
      "$\\tau_a$ 0.87\n",
      "soy stats: PRECISION, RECALL, F1 (0.24, 0.57, 0.34)\n",
      "------ done replacing ----------\n",
      "(4, 17, 7)\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 13 repairs 25 errors 18\n",
      "$\\tau_a$ 0.85\n",
      "peanut stats: PRECISION, RECALL, F1 (0.52, 0.72, 0.6)\n",
      "------ done replacing ----------\n",
      "(13, 25, 18)\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 0 repairs 10 errors 0\n",
      "$\\tau_a$ 0.86\n",
      "eggs stats: PRECISION, RECALL, F1 (0.0, 0, 0)\n",
      "------ done replacing ----------\n",
      "(0, 10, 0)\n",
      "correct_repairs, repairs, errors 31 104 58\n",
      "precision 0.3 recall 0.53\n",
      "recall 0.53\n",
      "F1 0.3831325301204819\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "dtest = dt.read_test_csv(dataName, parker)\n",
    "dtest1 = dtest.copy()\n",
    "print(dtest1.shape)\n",
    "print('+++++++++++++++++++++Start+++++++++++++++++++++++++++++')\n",
    "\n",
    "for a in labels:\n",
    "    # test repaired by parker do not have the following columns: need to fix it!!\n",
    "    if a + '_gs'not in dtest1.columns:\n",
    "        dtest1 = dtest1.merge(dt.read_gs_csv(dataName)[[partial_key, a ]], \n",
    "                              how='inner', on=partial_key, suffixes=('', '_gs'))\n",
    "    # confidence score for each attribute\n",
    "    conf_score = round(records[_with][model_name][a]['proba'],2)\n",
    "    ## load saved model\n",
    "    file_model_name = f\"./models/_{a}_classifier_{model_name}_{_with}.pth\"\n",
    "    with open(file_model_name, 'rb') as f: model = pickle.load(f)   \n",
    "\n",
    "    # get the encoder if exists and encode y_orig  y_gs\n",
    "    enc = {}\n",
    "    enc, y_orig, y_gs = tp.encode(encoder, a, dtest1)\n",
    "    print(\"------ done encoding ----------\")      \n",
    "    \n",
    "    # predict the values for the labels to be repaired\n",
    "    y_pred, outputs, dtest, accuracy = tr.clf_test(model, dtest1, a, dataset, enc)\n",
    "    print(\"------ done predicting ----------\")\n",
    "\n",
    "    if a + '_orig' not in dtest1.columns:\n",
    "        dtest1 = dtest1.merge(dtest1[[partial_key, a ]], \n",
    "                              how='inner', on=partial_key, suffixes=('', '_orig')) \n",
    "        print('current columns:', dtest1.columns)\n",
    "\n",
    "    # evaluate on ground truth\n",
    "    y_repair = eva.assign_repair(outputs, y_orig.values, y_pred, conf_score)\n",
    "    # stats\n",
    "    correct_repair, repair, errors = eva.get_stats(y_repair, y_orig.values, y_gs.values)\n",
    "    # metrics\n",
    "    metrics = eva.get_metrics(y_repair, y_orig.values, y_gs.values)\n",
    "    print(r'$\\tau_a$', conf_score)\n",
    "    print(a, 'stats: PRECISION, RECALL, F1', metrics)\n",
    "\n",
    "    if len(encoder)>0:\n",
    "        dtest1[a] = tp.decode(encoder[a], a, y_repair) #y_repair\n",
    "    else: dtest1[a] = y_repair\n",
    "    print(\"------ done replacing ----------\")\n",
    "    print(eva.get_stats(dtest1[a], y_orig.values, y_gs.values))\n",
    "\n",
    "crs, rs, es = eva.get_all_stats(dtest1, labels)\n",
    "print('correct_repairs, repairs, errors', crs, rs, es)\n",
    "print('precision', round(crs/rs,2), 'recall', round(crs/es,2))\n",
    "if es !=0 and rs!=0: \n",
    "    print('recall', round(crs/es,2))\n",
    "    print('F1', 2 * round(crs/rs,2) * round(crs/es,2)/(round(crs/rs,2) + round(crs/es,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be saved: ./data/allergens/repaired/allergens_count-vect-xgboost_ML_repair_with_parker_threshold.csv test data (298, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/allergens/repaired/allergens_count-vect-xgboost_ML_repair_with_parker_threshold.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = f\"./data/{dataset['data_dir']}/repaired/{dataset['data_dir']}_{model_name}_ML_repair_{_with}_threshold.csv\"\n",
    "print('File to be saved:', file, 'test data', dtest.shape)\n",
    "file2 = f\"data/{dataset['data_dir']}/{dataset['data_dir']}.csv\"\n",
    "\n",
    "dtest1.to_csv(file, quoting=csv.QUOTE_NONNUMERIC, index=False)\n",
    "\n",
    "# ./data/allergens/repaired/allergens_count-vect-xgboost_ML_repair_with_parker_threshold.csv\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative path ./data/allergens --before delete (1635, 18)\n",
      "--after delete (298, 18)\n",
      "+++++++++++++++++++++Start+++++++++++++++++++++++++++++\n",
      "(298, 18)\n",
      "label nuts avg proba 0.83 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.83, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 11 repairs 44 errors 22\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.25, 0.5, 0.33)\n",
      "correct repair 11 repairs 44 errors 22\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.25, 0.5, 0.33)\n",
      "correct repair 11 repairs 44 errors 22\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.25, 0.5, 0.33)\n",
      "correct repair 11 repairs 44 errors 22\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.25, 0.5, 0.33)\n",
      "correct repair 10 repairs 38 errors 22\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.26, 0.45, 0.33)\n",
      "correct repair 9 repairs 20 errors 22\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.45, 0.41, 0.43)\n",
      "correct repair 9 repairs 19 errors 22\n",
      " th 0.83\n",
      "stats: correct_repairs, repairs, errors (0.47, 0.41, 0.44)\n",
      "correct repair 0 repairs 0 errors 22\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0.0, 0)\n",
      "+++++++++++++++++++++done with nuts+++++++++++++++++++++++++++++\n",
      "\n",
      "label milk avg proba 0.87 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.87, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 2 repairs 33 errors 6\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.06, 0.33, 0.1)\n",
      "correct repair 2 repairs 33 errors 6\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.06, 0.33, 0.1)\n",
      "correct repair 2 repairs 33 errors 6\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.06, 0.33, 0.1)\n",
      "correct repair 2 repairs 33 errors 6\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.06, 0.33, 0.1)\n",
      "correct repair 2 repairs 31 errors 6\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.06, 0.33, 0.1)\n",
      "correct repair 2 repairs 27 errors 6\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.07, 0.33, 0.12)\n",
      "correct repair 2 repairs 22 errors 6\n",
      " th 0.87\n",
      "stats: correct_repairs, repairs, errors (0.09, 0.33, 0.14)\n",
      "correct repair 0 repairs 0 errors 6\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0.0, 0)\n",
      "+++++++++++++++++++++done with milk+++++++++++++++++++++++++++++\n",
      "\n",
      "label gluten avg proba 0.83 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.83, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 5 repairs 26 errors 5\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.19, 1.0, 0.32)\n",
      "correct repair 5 repairs 26 errors 5\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.19, 1.0, 0.32)\n",
      "correct repair 5 repairs 26 errors 5\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.19, 1.0, 0.32)\n",
      "correct repair 5 repairs 26 errors 5\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.19, 1.0, 0.32)\n",
      "correct repair 3 repairs 21 errors 5\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.14, 0.6, 0.23)\n",
      "correct repair 3 repairs 11 errors 5\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.27, 0.6, 0.37)\n",
      "correct repair 3 repairs 11 errors 5\n",
      " th 0.83\n",
      "stats: correct_repairs, repairs, errors (0.27, 0.6, 0.37)\n",
      "correct repair 0 repairs 0 errors 5\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0.0, 0)\n",
      "+++++++++++++++++++++done with gluten+++++++++++++++++++++++++++++\n",
      "\n",
      "label soy avg proba 0.87 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.87, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 4 repairs 28 errors 7\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.14, 0.57, 0.22)\n",
      "correct repair 4 repairs 28 errors 7\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.14, 0.57, 0.22)\n",
      "correct repair 4 repairs 28 errors 7\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.14, 0.57, 0.22)\n",
      "correct repair 4 repairs 28 errors 7\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.14, 0.57, 0.22)\n",
      "correct repair 4 repairs 26 errors 7\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.15, 0.57, 0.24)\n",
      "correct repair 4 repairs 20 errors 7\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.2, 0.57, 0.3)\n",
      "correct repair 4 repairs 17 errors 7\n",
      " th 0.87\n",
      "stats: correct_repairs, repairs, errors (0.24, 0.57, 0.34)\n",
      "correct repair 0 repairs 0 errors 7\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0.0, 0)\n",
      "+++++++++++++++++++++done with soy+++++++++++++++++++++++++++++\n",
      "\n",
      "label peanut avg proba 0.85 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.85, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 14 repairs 29 errors 18\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.48, 0.78, 0.59)\n",
      "correct repair 14 repairs 29 errors 18\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.48, 0.78, 0.59)\n",
      "correct repair 14 repairs 29 errors 18\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.48, 0.78, 0.59)\n",
      "correct repair 14 repairs 29 errors 18\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.48, 0.78, 0.59)\n",
      "correct repair 13 repairs 28 errors 18\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.46, 0.72, 0.56)\n",
      "correct repair 13 repairs 25 errors 18\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.52, 0.72, 0.6)\n",
      "correct repair 13 repairs 25 errors 18\n",
      " th 0.85\n",
      "stats: correct_repairs, repairs, errors (0.52, 0.72, 0.6)\n",
      "correct repair 0 repairs 0 errors 18\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0.0, 0)\n",
      "+++++++++++++++++++++done with peanut+++++++++++++++++++++++++++++\n",
      "\n",
      "label eggs avg proba 0.86 ths [0, 0.0, 0.2, 0.4, 0.6000000000000001, 0.8, 0.86, 1.0]\n",
      "------ done encoding ----------\n",
      "------ done predicting ----------\n",
      "correct repair 0 repairs 12 errors 0\n",
      " th 0\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 12 errors 0\n",
      " th 0.0\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 12 errors 0\n",
      " th 0.2\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 12 errors 0\n",
      " th 0.4\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 11 errors 0\n",
      " th 0.6000000000000001\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 10 errors 0\n",
      " th 0.8\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 10 errors 0\n",
      " th 0.86\n",
      "stats: correct_repairs, repairs, errors (0.0, 0, 0)\n",
      "correct repair 0 repairs 0 errors 0\n",
      " th 1.0\n",
      "stats: correct_repairs, repairs, errors (0, 0, 0)\n",
      "+++++++++++++++++++++done with eggs+++++++++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++++more sources+++++++++++++++++++++++++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "dtest = dt.read_test_csv(dataName, parker)\n",
    "\n",
    "print('+++++++++++++++++++++Start+++++++++++++++++++++++++++++')\n",
    "\n",
    "dtest1 = dtest.copy()\n",
    "print(dtest1.shape)\n",
    "\n",
    "for a in labels:\n",
    "    # test repaired by parker do not have the following columns: need to fix it!!\n",
    "    if a + '_gs'not in dtest1.columns:\n",
    "        dtest1 = dtest1.merge(dt.read_gs_csv(dataName)[[partial_key, a ]], \n",
    "                              how='inner', on=partial_key, suffixes=('', '_gs'))\n",
    "\n",
    "\n",
    "    avg_proba = round(records[_with][model_name][a]['proba'],2)\n",
    "\n",
    "    thresholds = [0, avg_proba] + [th for th in np.arange(0, 1.1, 0.2)]\n",
    "\n",
    "    ## load saved model\n",
    "    file_model_name = f\"./models/_{a}_classifier_{model_name}_{_with}.pth\"\n",
    "    with open(file_model_name, 'rb') as f: model = pickle.load(f)   \n",
    "\n",
    "    thresholds.sort()\n",
    "    print('label',a, 'avg proba', avg_proba, 'ths', thresholds)\n",
    "\n",
    "    # get the encoder if exists and encode y_orig  y_gs\n",
    "    enc = {}\n",
    "    enc, y_orig, y_gs = tp.encode(encoder, a, dtest1)\n",
    "    print(\"------ done encoding ----------\")      \n",
    "    \n",
    "    # predict the values for the labels to be repaired\n",
    "    y_pred, outputs, dtest, accuracy = tr.clf_test(model, dtest1, a, dataset, enc)\n",
    "    print(\"------ done predicting ----------\")\n",
    "\n",
    "    if a + '_orig' not in dtest1.columns:\n",
    "        dtest1 = dtest1.merge(dtest1[[partial_key, a ]], \n",
    "                              how='inner', on=partial_key, suffixes=('', '_orig')) \n",
    "        print('current columns:', dtest1.columns)\n",
    "    \n",
    "    repairs = []\n",
    "    correct_repairs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    # evaluate on ground truth\n",
    "    for th in  thresholds: \n",
    "        y_repair = eva.assign_repair(outputs, y_orig.values, y_pred, th)\n",
    "        # stats\n",
    "        correct_repair, repair, errors = eva.get_stats(y_repair, y_orig.values, y_gs.values)\n",
    "        correct_repairs.append(correct_repair)\n",
    "        repairs.append(repair)\n",
    "\n",
    "        # metrics\n",
    "        metrics = eva.get_metrics(y_repair, y_orig.values, y_gs.values)\n",
    "        recalls.append(round(metrics[1],2))\n",
    "        precisions.append(round(metrics[0],2))\n",
    "        f1s.append(round(metrics[2],2))\n",
    "\n",
    "        print(' th', th, )\n",
    "        print('stats: correct_repairs, repairs, errors', metrics)\n",
    "\n",
    "    stats[a] = {\"errors\": errors, \"avg_proba\": avg_proba,\\\n",
    "                \"threshold\": [round(th,2) for th in thresholds], 'repairs': repairs, 'correct_repairs': correct_repairs, \"precision\": precisions, \"recall\": recalls, \"F-1\": f1s}\n",
    "    print(f\"+++++++++++++++++++++done with {a}+++++++++++++++++++++++++++++\")\n",
    "    print()\n",
    "#         break\n",
    "print('+++++++++++++++++++++more sources+++++++++++++++++++++++++++++')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save statistics of models performences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/allergens/allergens_stats_count-vect-xgboost_with_parker.json\n"
     ]
    }
   ],
   "source": [
    "statFile = f\"./results/{dataset['data_dir']}/{dataset['data_dir']}_stats_{model_name}_{_with}.json\"\n",
    "print(statFile)\n",
    "with open(statFile, \"w\") as outfile: \n",
    "        json.dump(stats, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
